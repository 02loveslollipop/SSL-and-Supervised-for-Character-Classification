{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Large-Scale Image Preprocessing for SimCLR and Supervised Datasets\n",
        "\n",
        "This notebook preprocesses large image datasets by resizing, normalizing, and saving images and tensors for efficient loading in downstream experiments. It handles both SimCLR (unlabeled) and supervised (labeled) datasets, ensuring portability and memory efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "688ccb48",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 2. Image Transformations (Resize & Normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a39ac44",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e741e5e",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 3. Dataset retrieval and transformation for Self-Supervised Learning dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1b2d8f",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "N = 10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "output_dir = os.path.join(os.getcwd(), \"datasets\")\n",
        "pretrain_img_dir = os.path.join(output_dir, \"pretrain\")\n",
        "os.makedirs(pretrain_img_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(os.path.join(output_dir, \"pretrain.pt\")):\n",
        "    print(\"Pretrain dataset already exists. Loading...\")\n",
        "    pretrain_dataset = torch.load(os.path.join(output_dir, \"pretrain.pt\"), weights_only=False)\n",
        "else:\n",
        "    print(\"Pretrain dataset does not exist. Downloading and processing datasets...\")\n",
        "\n",
        "    ds1_path = kagglehub.dataset_download(\"soumikrakshit/anime-faces\")\n",
        "    ds2_path = kagglehub.dataset_download(\"stevenevan99/face-of-pixiv-top-daily-illustration-2020\")\n",
        "    ds3_path = kagglehub.dataset_download(\"hirunkulphimsiri/fullbody-anime-girls-datasets\")\n",
        "\n",
        "    dataset1 = datasets.ImageFolder(root=ds1_path, transform=transform)\n",
        "    dataset2 = datasets.ImageFolder(root=ds2_path, transform=transform)\n",
        "    dataset3 = datasets.ImageFolder(root=ds3_path, transform=transform)\n",
        "    pretrain_dataset = torch.utils.data.ConcatDataset([dataset1, dataset2, dataset3])\n",
        "\n",
        "    # Save processed images as PNG\n",
        "    idx = 1\n",
        "    for ds in [dataset1, dataset2, dataset3]:\n",
        "        for i in range(len(ds)):\n",
        "            img_tensor, _ = ds[i]\n",
        "            # Denormalize for saving as PNG\n",
        "            img = F.to_pil_image(img_tensor)\n",
        "            img.save(os.path.join(pretrain_img_dir, f\"{idx}.png\"))\n",
        "            idx += 1\n",
        "\n",
        "    torch.save(pretrain_dataset, os.path.join(output_dir, \"pretrain.pt\"))\n",
        "\n",
        "# Visualize n random images from the processed images\n",
        "def visualize_processed_images(img_dir, num_images=5):\n",
        "    img_files = sorted(os.listdir(img_dir))[:num_images]\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for ax, img_file in zip(axes, img_files):\n",
        "        img = Image.open(os.path.join(img_dir, img_file))\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(img_file)\n",
        "    plt.show()\n",
        "\n",
        "visualize_processed_images(pretrain_img_dir, num_images=N)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4468d8c6",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 4. Dataset retrieval and transformation for Supervised fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2230da8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive # Mount Google Drive to access dataset\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d641c7",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "N = 10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "\n",
        "output_dir = os.path.join(os.getcwd(), \"datasets\")\n",
        "finetune_img_dir = os.path.join(output_dir, \"finetune\")\n",
        "os.makedirs(finetune_img_dir, exist_ok=True)\n",
        "\n",
        "dataset_path_compressed = \"/content/gdrive/MyDrive/GenshinImageClassifier/dataset.zip\"\n",
        "\n",
        "if os.path.exists(os.path.join(output_dir, \"finetune.pt\")):\n",
        "    print(\"Finetune dataset already exists. Loading...\")\n",
        "    finetune_dataset = torch.load(os.path.join(output_dir, \"finetune.pt\"), weights_only=False)\n",
        "else:\n",
        "    if not os.path.exists(dataset_path_compressed):\n",
        "        print(f\"Dataset file at {dataset_path_compressed} does not exist. Please download it or update the path.\")\n",
        "\n",
        "    if not os.path.exists(os.getcwd() + \"/tmp/\"):\n",
        "        os.makedirs(os.getcwd() + \"/tmp/\")\n",
        "\n",
        "    print(f\"Copying dataset file to /tmp/ directory...\")\n",
        "    shutil.copy(dataset_path_compressed, os.getcwd() + \"/tmp/dataset.zip\")\n",
        "\n",
        "    with zipfile.ZipFile(os.getcwd() + \"/tmp/dataset.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(os.getcwd() + \"/tmp/\")\n",
        "\n",
        "    dataset_path = os.path.join(os.getcwd(), \"tmp\", \"dataset\")\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(f\"Dataset path {dataset_path} does not exist. Please check the extraction.\")\n",
        "\n",
        "    finetune_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "    # Save processed images as PNG\n",
        "    for i in range(len(finetune_dataset)):\n",
        "        img_tensor, _ = finetune_dataset[i]\n",
        "        img = F.to_pil_image(img_tensor)\n",
        "        img.save(os.path.join(finetune_img_dir, f\"{i+1}.png\"))\n",
        "\n",
        "    torch.save(finetune_dataset, os.path.join(output_dir, \"finetune.pt\"))\n",
        "\n",
        "def visualize_processed_images(img_dir, num_images=5):\n",
        "    img_files = sorted(os.listdir(img_dir))[:num_images]\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for ax, img_file in zip(axes, img_files):\n",
        "        img = Image.open(os.path.join(img_dir, img_file))\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(img_file)\n",
        "    plt.show()\n",
        "\n",
        "visualize_processed_images(finetune_img_dir, num_images=N)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458562ae",
      "metadata": {},
      "source": [
        "### 5. Zip and Save Preprocessed Images and Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056d886b",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "datasets_dir = os.path.join(os.getcwd(), \"datasets\")\n",
        "zip_path = os.path.join(os.getcwd(), \"datasets.zip\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(datasets_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, datasets_dir)\n",
        "            zipf.write(file_path, arcname)\n",
        "print(f\"Zipped datasets folder to {zip_path}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
