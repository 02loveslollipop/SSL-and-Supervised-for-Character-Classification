{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9kdcGDU0LIN"
   },
   "source": [
    "# Comparative Analysis of Self-Supervised and Supervised Pretraining Approaches for Genshin Impact Character Classification Using ResNet-18\n",
    "\n",
    "This notebook implements an experimental framework to compare self-supervised and supervised pretraining approaches for the task of Genshin Impact character classification using the ResNet-18 architecture. The goal is to evaluate the effectiveness of different pretraining strategies in leveraging limited labeled data for improved classification performance.\n",
    "\n",
    "## Required Libraries\n",
    "- PyTorch\n",
    "- Torchvision\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- Pandas\n",
    "- Scikit-learn\n",
    "- Seaborn\n",
    "- Hugging Face (Optional for model uploading)\n",
    "- Kaggle (for dataset management)\n",
    "\n",
    "## Key elements of the implementation:\n",
    "- **Image Preprocessing**:\n",
    "    - Image resizing to 256x256 pixels with stretching and no aspect ratio preservation.\n",
    "    - Normalization using ImageNet statistics.\n",
    "\n",
    "- **Data Augmentation**:\n",
    "    - Random cropping, horizontal flipping, color jittering, and Gaussian blur for SimCLR pretraining.\n",
    "    - Random scaling $[1.0, 1.5]$ with random center cropping, rotation $[-15^\\circ, 15^\\circ]$ and horizontal flipping for fine-tuning.\n",
    "\n",
    "- **Model Architecture**:\n",
    "    - ResNet-18 with a projection head for SimCLR pretraining.\n",
    "    - Classification MLP head for fine-tuning with 6 output classes.\n",
    "\n",
    "- **Training Configuration**:\n",
    "    - SimCLR pretraining with 500 epochs, batch size of 256, and a learning rate of 0.5.\n",
    "    - Fine-tuning with 100 epochs, batch size of 32, and a learning rate of 0.01, with gradual unfreezing ResNet layers.\n",
    "\n",
    "- **Loss Functions**:\n",
    "    - Contrastive loss with temperature scaling for SimCLR pretraining.\n",
    "    - Cross-entropy loss for classification fine-tuning.\n",
    "\n",
    "> The contrastive loss is computed using the cosine similarity between the projected features of positive pairs, while the classification loss is computed using the softmax output of the final classification layer.\n",
    "\n",
    "\n",
    "- **Evaluation Metrics**:\n",
    "    - Cross-validation with 5 folds to ensure robustness.\n",
    "    - Top-1 and Top-5 accuracy, F1-score, precision, recall, and confusion matrix analysis.\n",
    "    - Visualization of learned features using t-SNE and Grad-CAM for interpretability.\n",
    "\n",
    "- **Models Training Approaches**:\n",
    "    - Pure supervised training on final dataset. (Comparison baseline)\n",
    "    - Self-supervised pretraining on unlabeled dataset followed by fine-tuning by supervised training on the final dataset.\n",
    "    - Self-supervised pretraining on unlabeled dataset followed by fine-tuning by semi-supervised training on the final dataset + non labeled dataset.\n",
    "    - ImageNet supervised pretraining followed by fine-tuning by supervised training on the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1j0g1AzB_qrb"
   },
   "source": [
    "## 1. Dependencies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78r7e2ji_ujD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVEA0DV7PTpl"
   },
   "source": [
    "## 2.Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADuABP22Pdsu",
    "outputId": "296e71a0-9267-4cd4-b9b5-de1d22a7b20b"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(f\"Memory Available: {torch.cuda.get_device_properties(0).total_memory / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0) / (1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQI9PuZPPjzK",
    "outputId": "1b4febf3-a636-439a-a8f6-bdb9dd099a5b"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj3aBi5t_Rtq"
   },
   "source": [
    "## 3. Dataset retrieval and transformation for Self-Supervised Learning dataset\n",
    "- Download the Genshin Impact character dataset from Kaggle.\n",
    "- Apply image transformations.\n",
    "- Save as a single dataset for self-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "SU8ZdMR2yc_4",
    "outputId": "76f36061-336f-4351-e26f-c92f3e94487a"
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406] # Using ImageNet mean and std for normalization\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def create_portable_dataset(source_paths, output_path, transform=None, verbose=True):\n",
    "    \"\"\"Create a portable dataset by preloading all images and storing them in a single file.\"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating portable dataset at {output_path}\")\n",
    "    \n",
    "    # Load datasets without transformation to get original images\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i, path in enumerate(source_paths):\n",
    "        if verbose:\n",
    "            print(f\"Processing dataset {i+1}/{len(source_paths)} from {path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load dataset with identity transform to get raw images\n",
    "            dataset = datasets.ImageFolder(root=path, transform=transforms.ToTensor())\n",
    "            \n",
    "            # Create a loader without shuffling to preserve order\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=32, shuffle=False, num_workers=2\n",
    "            )\n",
    "            \n",
    "            # Process batches\n",
    "            for images, labels in tqdm(loader, desc=f\"Dataset {i+1}\", disable=not verbose):\n",
    "                # Apply the transform if provided\n",
    "                if transform is not None:\n",
    "                    transformed_images = []\n",
    "                    for img in images:\n",
    "                        # Convert tensor back to PIL for custom transforms\n",
    "                        from torchvision.transforms.functional import to_pil_image\n",
    "                        pil_img = to_pil_image(img)\n",
    "                        transformed_images.append(transform(pil_img))\n",
    "                    images = torch.stack(transformed_images)\n",
    "                \n",
    "                # Use the dataset index as a label offset\n",
    "                all_images.append(images)\n",
    "                all_labels.append(labels + i * 1000)  # Offset labels by 1000 for each dataset\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing dataset {path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(all_images) == 0:\n",
    "        raise ValueError(\"No images could be loaded from the provided paths.\")\n",
    "    \n",
    "    # Combine all images and labels\n",
    "    all_images = torch.cat(all_images, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total images: {all_images.shape[0]}\")\n",
    "        print(f\"Image shape: {all_images.shape[1:]}\")\n",
    "    \n",
    "    # Create a dictionary to save\n",
    "    portable_dataset = {\n",
    "        'images': all_images,\n",
    "        'labels': all_labels,\n",
    "    }\n",
    "    \n",
    "    # Save the dataset\n",
    "    torch.save(portable_dataset, output_path)\n",
    "    if verbose:\n",
    "        print(f\"Dataset saved to {output_path}\")\n",
    "        print(f\"File size: {os.path.getsize(output_path) / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "    return portable_dataset\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Create dataset directory\n",
    "datasets_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "os.makedirs(datasets_dir, exist_ok=True)\n",
    "\n",
    "# SSL dataset creation\n",
    "ssl_dataset_path = os.path.join(datasets_dir, \"ssl-dataset-portable.pt\")\n",
    "if os.path.exists(ssl_dataset_path):\n",
    "    print(\"SSL portable dataset already exists. Skipping creation.\")\n",
    "else:\n",
    "    print(\"Creating portable SSL dataset...\")\n",
    "    \n",
    "    # Download datasets from Kaggle\n",
    "    try:\n",
    "        ds1_path = kagglehub.dataset_download(\"soumikrakshit/anime-faces\")\n",
    "        ds2_path = kagglehub.dataset_download(\"stevenevan99/face-of-pixiv-top-daily-illustration-2020\")\n",
    "        ds3_path = kagglehub.dataset_download(\"hirunkulphimsiri/fullbody-anime-girls-datasets\")\n",
    "        \n",
    "        # Create SSL dataset\n",
    "        create_portable_dataset(\n",
    "            [ds1_path, ds2_path, ds3_path],\n",
    "            ssl_dataset_path,\n",
    "            transform=transform\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating SSL dataset: {e}\")\n",
    "\n",
    "class PortableDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for loading preprocessed portable datasets.\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        self.data = torch.load(file_path)\n",
    "        self.images = self.data['images']\n",
    "        self.labels = self.data['labels']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Load SSL dataset\n",
    "if os.path.exists(ssl_dataset_path):\n",
    "    ssl_dataset = PortableDataset(ssl_dataset_path)\n",
    "    print(f\"SSL dataset loaded with {len(ssl_dataset)} images\")\n",
    "else:\n",
    "    print(\"SSL dataset not found. Please run the dataset creation block first.\")\n",
    "    ssl_dataset = None\n",
    "\n",
    "def visualize_dataset(dataset, num_images=5, title=None):\n",
    "    \"\"\"Visualize random samples from a dataset.\"\"\"\n",
    "    if dataset is None:\n",
    "        print(\"Dataset is not available for visualization.\")\n",
    "        return\n",
    "        \n",
    "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "    images = [dataset[i][0] for i in indices]\n",
    "    labels = [dataset[i][1] for i in indices]\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for ax, img, label in zip(axes, images, labels):\n",
    "        # Denormalize image for visualization\n",
    "        img_np = img.numpy().transpose(1, 2, 0)\n",
    "        mean = np.array(IMAGENET_MEAN)\n",
    "        std = np.array(IMAGENET_STD)\n",
    "        img_np = std * img_np + mean\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        \n",
    "        ax.imshow(img_np)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Label: {label.item()}\")\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from SSL dataset\n",
    "if ssl_dataset:\n",
    "    visualize_dataset(ssl_dataset, num_images=10, title=\"SSL Dataset Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz8m0jvdPx04"
   },
   "source": [
    "## 4. Dataset retrieval and transformation for Supervised fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3Rz1s4JOdqU",
    "outputId": "8f364553-a5b3-43ef-8aa6-92b23fa0057e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive # Mount Google Drive to access dataset\n",
    "drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "TDa9pu3CQkAp",
    "outputId": "9e80b84e-b03a-47e3-8d6a-d68f3efceba4"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Fine-tuning dataset creation\n",
    "finetune_dataset_path = os.path.join(datasets_dir, \"finetune-dataset-portable.pt\")\n",
    "if os.path.exists(finetune_dataset_path):\n",
    "    print(\"Fine-tuning portable dataset already exists. Skipping creation.\")\n",
    "else:\n",
    "    print(\"Creating portable fine-tuning dataset...\")\n",
    "    \n",
    "    dataset_path_compressed = \"/content/gdrive/MyDrive/GenshinImageClassifier/dataset.zip\"\n",
    "    if not os.path.exists(dataset_path_compressed):\n",
    "        print(f\"Dataset file at {dataset_path_compressed} does not exist. Please download it or update the path.\")\n",
    "    else:\n",
    "        # Prepare temp directory\n",
    "        tmp_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy and extract dataset\n",
    "        print(f\"Copying dataset file to tmp directory...\")\n",
    "        shutil.copy(dataset_path_compressed, os.path.join(tmp_dir, \"dataset.zip\"))\n",
    "        \n",
    "        # Unzip the dataset\n",
    "        with zipfile.ZipFile(os.path.join(tmp_dir, \"dataset.zip\"), 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmp_dir)\n",
    "        \n",
    "        # Create portable dataset\n",
    "        dataset_path = os.path.join(tmp_dir, \"dataset\")\n",
    "        create_portable_dataset(\n",
    "            [dataset_path],\n",
    "            finetune_dataset_path,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "# Load fine-tuning dataset\n",
    "if os.path.exists(finetune_dataset_path):\n",
    "    dataset = PortableDataset(finetune_dataset_path)\n",
    "    print(f\"Fine-tuning dataset loaded with {len(dataset)} images\")\n",
    "else:\n",
    "    print(\"Fine-tuning dataset not found. Please run the dataset creation block first.\")\n",
    "    dataset = None\n",
    "\n",
    "# Visualize samples from fine-tuning dataset\n",
    "if dataset:\n",
    "    visualize_dataset(dataset, num_images=10, title=\"Fine-tuning Dataset Samples\")import zipfile\n",
    "import shutil\n",
    "\n",
    "# Fine-tuning dataset creation\n",
    "finetune_dataset_path = os.path.join(datasets_dir, \"finetune-dataset-portable.pt\")\n",
    "if os.path.exists(finetune_dataset_path):\n",
    "    print(\"Fine-tuning portable dataset already exists. Skipping creation.\")\n",
    "else:\n",
    "    print(\"Creating portable fine-tuning dataset...\")\n",
    "    \n",
    "    dataset_path_compressed = \"/content/gdrive/MyDrive/GenshinImageClassifier/dataset.zip\"\n",
    "    if not os.path.exists(dataset_path_compressed):\n",
    "        print(f\"Dataset file at {dataset_path_compressed} does not exist. Please download it or update the path.\")\n",
    "    else:\n",
    "        # Prepare temp directory\n",
    "        tmp_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy and extract dataset\n",
    "        print(f\"Copying dataset file to tmp directory...\")\n",
    "        shutil.copy(dataset_path_compressed, os.path.join(tmp_dir, \"dataset.zip\"))\n",
    "        \n",
    "        # Unzip the dataset\n",
    "        with zipfile.ZipFile(os.path.join(tmp_dir, \"dataset.zip\"), 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmp_dir)\n",
    "        \n",
    "        # Create portable dataset\n",
    "        dataset_path = os.path.join(tmp_dir, \"dataset\")\n",
    "        create_portable_dataset(\n",
    "            [dataset_path],\n",
    "            finetune_dataset_path,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "# Load fine-tuning dataset\n",
    "if os.path.exists(finetune_dataset_path):\n",
    "    dataset = PortableDataset(finetune_dataset_path)\n",
    "    print(f\"Fine-tuning dataset loaded with {len(dataset)} images\")\n",
    "else:\n",
    "    print(\"Fine-tuning dataset not found. Please run the dataset creation block first.\")\n",
    "    dataset = None\n",
    "\n",
    "# Visualize samples from fine-tuning dataset\n",
    "if dataset:\n",
    "    visualize_dataset(dataset, num_images=10, title=\"Fine-tuning Dataset Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEZpG5HYWUnj"
   },
   "source": [
    "## 5. Models training, evaluation and feature extraction/visualization\n",
    "- Train the baseline model on the final dataset.\n",
    "- Train the self-supervised model on the unlabeled dataset.\n",
    "- Fine-tune the self-supervised model on the final dataset using supervised training.\n",
    "- Fine-tune the self-supervised model on the final dataset using semi-supervised training.\n",
    "- Fine-tune the ImageNet pre-trained model on the final dataset using supervised training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mof62Jz7Ztq9"
   },
   "source": [
    "### 5.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrdLE45ndgeH",
    "outputId": "19f5455b-b979-46e1-8168-d8a7fa77c2eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import copy\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "K_FOLDS = 5\n",
    "\n",
    "# Initialize 5-fold cross-validation\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Storage for results across folds\n",
    "fold_results = {\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'val_losses': [],\n",
    "    'val_accuracies': [],\n",
    "    'test_metrics': []\n",
    "}\n",
    "\n",
    "# Get all indices for the dataset\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "print(f\"Starting {K_FOLDS}-fold cross-validation on {dataset_size} samples...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{K_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Create data samplers for train and validation\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE, sampler=train_sampler\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE, sampler=val_sampler\n",
    "    )\n",
    "\n",
    "    # Initialize model for this fold\n",
    "    model = models.resnet18(weights=None, num_classes=6).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Storage for this fold's training history\n",
    "    fold_train_losses = []\n",
    "    fold_train_accuracies = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_accuracies = []\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Training loop for this fold\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_idx)\n",
    "        epoch_train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_idx)\n",
    "        epoch_val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Store metrics\n",
    "        fold_train_losses.append(epoch_train_loss)\n",
    "        fold_train_accuracies.append(epoch_train_accuracy)\n",
    "        fold_val_losses.append(epoch_val_loss)\n",
    "        fold_val_accuracies.append(epoch_val_accuracy)\n",
    "\n",
    "        # Save best model\n",
    "        if epoch_val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = epoch_val_accuracy\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # Print progress every 50 epochs\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "            print(f\"  Train - Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_accuracy:.2f}%\")\n",
    "            print(f\"  Val   - Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_accuracy:.2f}%\")\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Final evaluation on validation set (as test set for this fold)\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate detailed metrics for this fold\n",
    "    fold_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    fold_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    fold_precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    fold_recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    # Store fold results\n",
    "    fold_results['train_losses'].append(fold_train_losses)\n",
    "    fold_results['train_accuracies'].append(fold_train_accuracies)\n",
    "    fold_results['val_losses'].append(fold_val_losses)\n",
    "    fold_results['val_accuracies'].append(fold_val_accuracies)\n",
    "    fold_results['test_metrics'].append({\n",
    "        'accuracy': fold_accuracy,\n",
    "        'f1': fold_f1,\n",
    "        'precision': fold_precision,\n",
    "        'recall': fold_recall\n",
    "    })\n",
    "\n",
    "    print(f\"\\nFold {fold + 1} Results:\")\n",
    "    print(f\"  Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "    print(f\"  Test Accuracy: {fold_accuracy*100:.2f}%\")\n",
    "    print(f\"  Test F1-Score: {fold_f1:.4f}\")\n",
    "    print(f\"  Test Precision: {fold_precision:.4f}\")\n",
    "    print(f\"  Test Recall: {fold_recall:.4f}\")\n",
    "\n",
    "# Calculate and display overall results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Extract test metrics\n",
    "test_accuracies = [fold['accuracy'] for fold in fold_results['test_metrics']]\n",
    "test_f1_scores = [fold['f1'] for fold in fold_results['test_metrics']]\n",
    "test_precisions = [fold['precision'] for fold in fold_results['test_metrics']]\n",
    "test_recalls = [fold['recall'] for fold in fold_results['test_metrics']]\n",
    "\n",
    "# Calculate statistics\n",
    "print(f\"Test Accuracy:  {np.mean(test_accuracies)*100:.2f}% ± {np.std(test_accuracies)*100:.2f}%\")\n",
    "print(f\"Test F1-Score:  {np.mean(test_f1_scores):.4f} ± {np.std(test_f1_scores):.4f}\")\n",
    "print(f\"Test Precision: {np.mean(test_precisions):.4f} ± {np.std(test_precisions):.4f}\")\n",
    "print(f\"Test Recall:    {np.mean(test_recalls):.4f} ± {np.std(test_recalls):.4f}\")\n",
    "\n",
    "# Plot training curves for all folds\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Average training loss\n",
    "avg_train_losses = np.mean(fold_results['train_losses'], axis=0)\n",
    "std_train_losses = np.std(fold_results['train_losses'], axis=0)\n",
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "axes[0, 0].plot(epochs_range, avg_train_losses, 'b-', label='Mean Training Loss')\n",
    "axes[0, 0].fill_between(epochs_range,\n",
    "                       avg_train_losses - std_train_losses,\n",
    "                       avg_train_losses + std_train_losses,\n",
    "                       alpha=0.3, color='blue')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Average Training Loss Across Folds')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Average validation loss\n",
    "avg_val_losses = np.mean(fold_results['val_losses'], axis=0)\n",
    "std_val_losses = np.std(fold_results['val_losses'], axis=0)\n",
    "\n",
    "axes[0, 1].plot(epochs_range, avg_val_losses, 'r-', label='Mean Validation Loss')\n",
    "axes[0, 1].fill_between(epochs_range,\n",
    "                       avg_val_losses - std_val_losses,\n",
    "                       avg_val_losses + std_val_losses,\n",
    "                       alpha=0.3, color='red')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Average Validation Loss Across Folds')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Average training accuracy\n",
    "avg_train_acc = np.mean(fold_results['train_accuracies'], axis=0)\n",
    "std_train_acc = np.std(fold_results['train_accuracies'], axis=0)\n",
    "\n",
    "axes[1, 0].plot(epochs_range, avg_train_acc, 'g-', label='Mean Training Accuracy')\n",
    "axes[1, 0].fill_between(epochs_range,\n",
    "                       avg_train_acc - std_train_acc,\n",
    "                       avg_train_acc + std_train_acc,\n",
    "                       alpha=0.3, color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].set_title('Average Training Accuracy Across Folds')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Average validation accuracy\n",
    "avg_val_acc = np.mean(fold_results['val_accuracies'], axis=0)\n",
    "std_val_acc = np.std(fold_results['val_accuracies'], axis=0)\n",
    "\n",
    "axes[1, 1].plot(epochs_range, avg_val_acc, 'm-', label='Mean Validation Accuracy')\n",
    "axes[1, 1].fill_between(epochs_range,\n",
    "                       avg_val_acc - std_val_acc,\n",
    "                       avg_val_acc + std_val_acc,\n",
    "                       alpha=0.3, color='magenta')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "axes[1, 1].set_title('Average Validation Accuracy Across Folds')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for test metrics comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "metrics_names = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "metrics_means = [np.mean(test_accuracies)*100, np.mean(test_f1_scores)*100,\n",
    "                np.mean(test_precisions)*100, np.mean(test_recalls)*100]\n",
    "metrics_stds = [np.std(test_accuracies)*100, np.std(test_f1_scores)*100,\n",
    "               np.std(test_precisions)*100, np.std(test_recalls)*100]\n",
    "\n",
    "x_pos = np.arange(len(metrics_names))\n",
    "bars = ax.bar(x_pos, metrics_means, yerr=metrics_stds, capsize=5,\n",
    "              color=['skyblue', 'lightgreen', 'lightcoral', 'lightsalmon'])\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score (%)')\n",
    "ax.set_title('Cross-Validation Test Metrics (Mean ± Std)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(metrics_names)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean_val, std_val in zip(bars, metrics_means, metrics_stds):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + std_val + 0.5,\n",
    "            f'{mean_val:.1f}±{std_val:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ssl-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
